{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection with backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for importing dataset\n",
    "import numpy as np \n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "df=pd.read_csv('abalone.csv')\n",
    "print(\"Shape:\\n\",df.shape)\n",
    "print(\"\")\n",
    "#First 5 instances of the dataset\n",
    "print(\"First 5 rows:\\n\",df.head())\n",
    "print(\"\")\n",
    "#this is initializing x with 8 given attributes and its instances\n",
    "x=df.iloc[:,:-1]\n",
    "x.shape\n",
    "print(\"X:\\n\",x.head())\n",
    "print(\"\")\n",
    "#this is initializing y with classlabel and its instances\n",
    "y=df.iloc[:,8]\n",
    "y.shape\n",
    "print(\"Y:\\n\",y.head())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming column sex that is a categorical data into numerical data\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "columnTransformer = ColumnTransformer([('sex', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = columnTransformer.fit_transform(x)\n",
    "pd.DataFrame(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoiding the dummy variable trap:\n",
    "x=x[:,1:]\n",
    "#printing entire day\n",
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "#70% training (x) and 30% is test (y)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mlr=LinearRegression()\n",
    "mlr.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "y_pred=mlr.predict(x_test)\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score:\",r2_score(y_test,y_pred)*100)\n",
    "\n",
    "#by using Linear Regression R2 Score we get 52.48%\n",
    "# using Linear Regression we are applying all independent variables\n",
    "# (All independent values) x = D1,D2,length,diameter,height,whole weight,shucked weight,viscera weight,shall weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now from all independent values we will find the best independent feature\n",
    "\n",
    "#Backward Elimination:\n",
    "\n",
    "import statsmodels.api as sm\n",
    "# Doing this because the bias value is not being assign automatically in BE as in LR y=mx+b the b(intercept) is assigned\n",
    "# automatically.\n",
    "X=np.append(arr=np.ones((4177,1)).astype(int), values=x,axis=1)\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking all rows and all column\n",
    "X_opt=X[:,:]\n",
    "regressor_OLS=sm.OLS(endog=y,exog=X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "#Have to remove 2 features one by one as fulling the condition P>0.05\n",
    "#choosing the highest p value that is 0.8 x3 that is length and removing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed the Length column which was x3 because it P value was higher than 0.05\n",
    "#x0,x1,x2,x4,x5,x6,x7,x8,x9\n",
    "#Intercept,D1,D2,diameter,height,whole weight,shucked weight,viscera weight,shall weight\n",
    "X_opt=X[:,[0,1,2,4,5,6,7,8,9]]\n",
    "regressor_OLS=sm.OLS(endog=y,exog=X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "#As x2 which is Dummy variable 2 needs to be removed as its p value is 0.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed the D2 column which was x2 because it P value was higher than 0.05\n",
    "X_opt=X[:,[0,1,4,5,6,7,8,9]]\n",
    "regressor_OLS=sm.OLS(endog=y,exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the remaining columns \n",
    "#x0,x1,x2,x4,x5,x6,x7\n",
    "#Intercept,D1,diameter,height,whole weight,shucked weight,viscera weight,shall weight\n",
    "\n",
    "#Importing the dataset\n",
    "df1=pd.read_csv('abalone.csv')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.drop([\"length\"],axis='columns')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature='rings'\n",
    "\n",
    "#Separate object for target feature\n",
    "y=df2[target_feature]\n",
    "\n",
    "#Seperate object from input features\n",
    "X=df2.drop(target_feature,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "columnTransformer = ColumnTransformer([('sex', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = columnTransformer.fit_transform(X)\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoiding the dummy variable trap:\n",
    "X=X[:,1:]\n",
    "#printing entire day\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,[0,2,3,4,5,6,7]]\n",
    "pd.DataFrame(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#80% training (x) and 20% is test (y)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y, test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regr=LinearRegression()\n",
    "regr.fit(x_train,y_train)\n",
    "regr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "r2Score=cross_val_score(estimator=regr,X=x_train,y=y_train,cv=10)\n",
    "print(\"R2 Score Avg:{:.2f}%\".format((r2Score.mean()*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for importing dataset\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "df=pd.read_csv('abalone.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is initializing x with 8 given attributes and its instances\n",
    "x=df.iloc[:,:-1]\n",
    "x.shape\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is initializing y with classlabel and its instances\n",
    "y=df.iloc[:,8]\n",
    "y.shape\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "columnTransformer = ColumnTransformer([('sex', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = columnTransformer.fit_transform(x)\n",
    "\n",
    "#Avoiding the dummy variable trap:\n",
    "x=x[:,1:]\n",
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#70% training (x) and 30% is test (y)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.3,random_state=1)\n",
    "x_train.shape, x_test.shape,y_train.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#sq(4177) = 64.6 round off to 65\n",
    "classifier=KNeighborsClassifier(n_neighbors=65)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy=cross_val_score(estimator=classifier,X=x_train,y=y_train,cv=10)\n",
    "print(\"Accuracy:{:.2f}%\".format((accuracy.mean()*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_pred=classifier.predict(x_test)\n",
    "print(\"Precision:{:.2f}%\".format(precision_score(y_test,y_pred,average=\"micro\")*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_pred=classifier.predict(x_test)\n",
    "print(\"Recall:{:.2f}%\".format(recall_score(y_test,y_pred,average='micro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_pred=classifier.predict(x_test)\n",
    "print(\"Sensitivity:{:.2f}%\".format(recall_score(y_test,y_pred,average='micro')*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for importing dataset\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Importing the dataset\n",
    "df=pd.read_csv('abalone.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is initializing x with 8 given attributes and its instances\n",
    "x=df.iloc[:,:-1]\n",
    "x.shape\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is initializing y with classlabel and its instances\n",
    "y=df.iloc[:,8]\n",
    "y.shape\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "#columnTransformer = ColumnTransformer([('sex', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "#x = columnTransformer.fit_transform(x)\n",
    "\n",
    "#Avoiding the dummy variable trap:\n",
    "\n",
    "#pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=x[:,1:]\n",
    "#pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_x=LabelEncoder()\n",
    "x.iloc[:,0]= labelencoder_x.fit_transform(x.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#70% training (x) and 30% is test (y)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.3,random_state=1)\n",
    "x_train.shape, x_test.shape,y_train.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"sex\",\"length\",\"diameter\",\"height\",\"whole weight\",\"shucked weight\",\"viscera weight\",\"shall weight\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "estimator = Id3Estimator()\n",
    "estimator.fit(x_train, y_train)\n",
    "export_graphviz(estimator.tree_, 'tree.dot',feature_names)\n",
    "predictions = estimator.predict(x_test) \n",
    "print(x_test)\n",
    "print(\"Predicted class label for new Data point : \" ,predictions[0]);\n",
    "\n",
    "from graphviz import render\n",
    "\n",
    "render('dot', 'png', 'E:/Softwares/OneDrive/Desktop/Machine Learning/Project/Dataset/Abalone/tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_tree = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "clf_tree.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dotfile = open(\"E:/Softwares/OneDrive/Desktop/Machine Learning/Project/Dataset/Abalone/treeID3.dot\", 'w')\n",
    "tree.export_graphviz(clf_tree, out_file = dotfile)\n",
    "dotfile.close()\n",
    "\n",
    "\n",
    "#from graphviz import render\n",
    "\n",
    "#render('dot', 'png', 'E:/Softwares/OneDrive/Desktop/Machine Learning/Project/Dataset/Abalone/treeID3.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy=cross_val_score(estimator=clf_tree,X=x_train,y=y_train,cv=10)\n",
    "print(\"Accuracy:{:.2f}%\".format((accuracy.mean()*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_pred=estimator.predict(x_test)\n",
    "print(\"Sensitivity:{:.2f}%\".format(recall_score(y_test,y_pred,average='micro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_pred=estimator.predict(x_test)\n",
    "print(\"Recall:{:.2f}%\".format(recall_score(y_test,y_pred,average='micro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_pred=estimator.predict(x_test)\n",
    "print(\"Sensitivity:{:.2f}%\".format(recall_score(y_test,y_pred,average='micro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "#fig, ax = plt.subplots(figsize=(100,100))\n",
    "#tree.plot_tree(clf_tree, fontsize=10)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
